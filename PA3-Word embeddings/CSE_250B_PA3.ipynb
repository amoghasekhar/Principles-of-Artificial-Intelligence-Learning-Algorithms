{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create V, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\pin_t\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pin_t\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pin_t\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place . The jury further said in term-end present\n"
     ]
    }
   ],
   "source": [
    "words = ' '.join(brown.words())\n",
    "print (words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "stop = set(stopwords.words('english'))\n",
    "wordsNew = [word for word in word_tokenize(words.lower()) if word not in stop and word.isalpha()]\n",
    "wordsNew = np.asarray(wordsNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515753"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordsNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsCount = Counter(wordsNew)\n",
    "V = np.asarray([e[0] for e in wordsCount.most_common(5000)])\n",
    "C = V[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate P(c) and P(c|w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2map(words):\n",
    "    word2idx = defaultdict(int);\n",
    "    for word in words:\n",
    "        word2idx[word] = len(word2idx)\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "V2idx = word2map(V);\n",
    "C2idx = word2map(C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting context appearance...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "V_SIZE = len(V)\n",
    "C_SIZE = len(C)\n",
    "HALF_WINDOW = 2\n",
    "M = len(wordsNew)\n",
    "\n",
    "# prepare for the calculation of Pr(c) and Pr(c|w)\n",
    "# use ones to apply laplace smoothing\n",
    "print (\"counting context appearance...\")\n",
    "window_count = np.ones((V_SIZE, C_SIZE))\n",
    "core_count = np.ones((1, C_SIZE))\n",
    "for i in range(M):\n",
    "    w = wordsNew[i]\n",
    "    if not w in V2idx:\n",
    "        continue\n",
    "    else:\n",
    "        wid = V2idx[w]\n",
    "    for j in range(i - HALF_WINDOW, i + HALF_WINDOW + 1):\n",
    "        if j < 0 or j >= M or j == i:\n",
    "            continue\n",
    "        c = wordsNew[j]\n",
    "        if not c in C2idx:\n",
    "            continue\n",
    "        else:\n",
    "            cid = C2idx[c]\n",
    "        window_count[wid][cid] += 1\n",
    "        core_count[0][cid] += 1\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating probability...\n",
      "saving representation...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# calculate Pr(c) and Pr(c|w)\n",
    "print (\"calculating probability...\")\n",
    "pwc, pc = window_count, core_count\n",
    "for i in range(len(pwc)):\n",
    "    pwc[i] = pwc[i] / pwc[i].sum()\n",
    "pc = pc / pc.sum()\n",
    "\n",
    "# calculate pointwise mutual information\n",
    "r = np.zeros((V_SIZE, C_SIZE))\n",
    "for i in range(V_SIZE):\n",
    "    for j in range(C_SIZE):\n",
    "        r[i][j] = max(0, log(pwc[i][j] /  pc[0][j]))\n",
    "\n",
    "# save representation matrix to file\n",
    "print (\"saving representation...\")\n",
    "np.save(\"representation-\" + str(C_SIZE) + \".npy\", r)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "U_SIZE = 100\n",
    "r = np.load(\"representation-\" + str(C_SIZE) + \".npy\");\n",
    "pca = PCA(n_components = U_SIZE);\n",
    "cr = pca.fit_transform(r);\n",
    "np.save(\"representation-\" + str(U_SIZE) + \".npy\", cr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2word(words):\n",
    "    idx2word = defaultdict(str);\n",
    "    for i, word in enumerate(words):\n",
    "        idx2word[i] = word\n",
    "    return idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2V = map2word(V)\n",
    "idx2C = map2word(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jim\n",
      "bobbie\n",
      "damn\n",
      "recall\n",
      "intelligent\n",
      "drunk\n",
      "hated\n",
      "dawn\n",
      "succeeded\n",
      "mistake\n",
      "jersey\n",
      "tim\n",
      "hoping\n",
      "nowhere\n",
      "visiting\n",
      "chicken\n",
      "worst\n",
      "violent\n",
      "doctors\n",
      "libraries\n",
      "\n",
      "******************************\n",
      "question\n",
      "change\n",
      "rather\n",
      "matter\n",
      "thus\n",
      "problem\n",
      "means\n",
      "example\n",
      "policy\n",
      "problems\n",
      "experience\n",
      "field\n",
      "human\n",
      "action\n",
      "community\n",
      "whole\n",
      "important\n",
      "economic\n",
      "interest\n",
      "point\n",
      "\n",
      "******************************\n",
      "activity\n",
      "distribution\n",
      "mass\n",
      "indicated\n",
      "applied\n",
      "latter\n",
      "maximum\n",
      "analysis\n",
      "obtained\n",
      "parts\n",
      "materials\n",
      "unit\n",
      "rise\n",
      "figures\n",
      "described\n",
      "cells\n",
      "somewhat\n",
      "gas\n",
      "showed\n",
      "using\n",
      "\n",
      "******************************\n",
      "revenues\n",
      "surplus\n",
      "districts\n",
      "safety\n",
      "transportation\n",
      "concerns\n",
      "abroad\n",
      "amounts\n",
      "finance\n",
      "farmers\n",
      "shooting\n",
      "estate\n",
      "contribute\n",
      "hopes\n",
      "devoted\n",
      "developments\n",
      "legislation\n",
      "financing\n",
      "difficulties\n",
      "electronics\n",
      "\n",
      "******************************\n",
      "difficult\n",
      "believe\n",
      "hope\n",
      "therefore\n",
      "century\n",
      "idea\n",
      "view\n",
      "freedom\n",
      "indeed\n",
      "attention\n",
      "england\n",
      "seem\n",
      "common\n",
      "able\n",
      "spirit\n",
      "true\n",
      "nations\n",
      "future\n",
      "society\n",
      "america\n",
      "\n",
      "******************************\n",
      "bag\n",
      "shorts\n",
      "burned\n",
      "instant\n",
      "stranger\n",
      "ramey\n",
      "noticed\n",
      "watson\n",
      "fallen\n",
      "darkness\n",
      "plain\n",
      "jess\n",
      "yard\n",
      "roberts\n",
      "glance\n",
      "fired\n",
      "jumped\n",
      "pair\n",
      "bent\n",
      "brush\n",
      "\n",
      "******************************\n",
      "fluid\n",
      "oxidation\n",
      "reaches\n",
      "zero\n",
      "atoms\n",
      "variation\n",
      "cm\n",
      "equation\n",
      "sufficiently\n",
      "pond\n",
      "surrounding\n",
      "applying\n",
      "muscle\n",
      "strain\n",
      "carbon\n",
      "apparatus\n",
      "composition\n",
      "depending\n",
      "v\n",
      "samples\n",
      "\n",
      "******************************\n",
      "ideas\n",
      "religion\n",
      "terms\n",
      "involved\n",
      "moral\n",
      "responsibility\n",
      "organization\n",
      "needs\n",
      "effect\n",
      "science\n",
      "nature\n",
      "personal\n",
      "christian\n",
      "basic\n",
      "evidence\n",
      "religious\n",
      "particular\n",
      "population\n",
      "modern\n",
      "situation\n",
      "\n",
      "******************************\n",
      "perhaps\n",
      "kind\n",
      "quite\n",
      "whether\n",
      "seemed\n",
      "become\n",
      "least\n",
      "yet\n",
      "possible\n",
      "today\n",
      "sense\n",
      "case\n",
      "need\n",
      "country\n",
      "order\n",
      "though\n",
      "best\n",
      "different\n",
      "fact\n",
      "shall\n",
      "\n",
      "******************************\n",
      "f\n",
      "pencil\n",
      "hence\n",
      "tangent\n",
      "n\n",
      "curve\n",
      "meets\n",
      "vertex\n",
      "e\n",
      "ordinary\n",
      "fixed\n",
      "frame\n",
      "column\n",
      "plane\n",
      "article\n",
      "base\n",
      "interior\n",
      "sides\n",
      "mold\n",
      "follows\n",
      "\n",
      "******************************\n",
      "recognize\n",
      "aware\n",
      "interesting\n",
      "follow\n",
      "whatever\n",
      "teacher\n",
      "interests\n",
      "complex\n",
      "remains\n",
      "indicate\n",
      "reasons\n",
      "significant\n",
      "obviously\n",
      "character\n",
      "attitude\n",
      "performance\n",
      "concept\n",
      "obvious\n",
      "concern\n",
      "manner\n",
      "\n",
      "******************************\n",
      "assembly\n",
      "december\n",
      "louis\n",
      "boston\n",
      "september\n",
      "richard\n",
      "robert\n",
      "reports\n",
      "friday\n",
      "announced\n",
      "official\n",
      "august\n",
      "writer\n",
      "eisenhower\n",
      "jones\n",
      "presented\n",
      "election\n",
      "planned\n",
      "officials\n",
      "october\n",
      "\n",
      "******************************\n",
      "efforts\n",
      "plans\n",
      "aid\n",
      "throughout\n",
      "leaders\n",
      "justice\n",
      "europe\n",
      "army\n",
      "kennedy\n",
      "entire\n",
      "nation\n",
      "council\n",
      "congress\n",
      "strength\n",
      "democratic\n",
      "member\n",
      "press\n",
      "western\n",
      "issue\n",
      "soviet\n",
      "\n",
      "******************************\n",
      "standing\n",
      "waited\n",
      "clothes\n",
      "rose\n",
      "bit\n",
      "dropped\n",
      "stopped\n",
      "horse\n",
      "moving\n",
      "closed\n",
      "mike\n",
      "caught\n",
      "kitchen\n",
      "beside\n",
      "deep\n",
      "thin\n",
      "forward\n",
      "ran\n",
      "teeth\n",
      "bright\n",
      "\n",
      "******************************\n",
      "rebel\n",
      "di\n",
      "bet\n",
      "commented\n",
      "buck\n",
      "crown\n",
      "camps\n",
      "crop\n",
      "dishes\n",
      "whip\n",
      "dick\n",
      "abuse\n",
      "clock\n",
      "hidden\n",
      "ridiculous\n",
      "plate\n",
      "marble\n",
      "landscape\n",
      "shocked\n",
      "wit\n",
      "\n",
      "******************************\n",
      "exploration\n",
      "solved\n",
      "aroused\n",
      "observation\n",
      "attract\n",
      "valid\n",
      "occurs\n",
      "disaster\n",
      "enable\n",
      "cope\n",
      "consistently\n",
      "encounter\n",
      "broader\n",
      "utterly\n",
      "diffusion\n",
      "respects\n",
      "inadequate\n",
      "exceptions\n",
      "stressed\n",
      "sharing\n",
      "\n",
      "******************************\n",
      "demand\n",
      "prices\n",
      "wage\n",
      "increases\n",
      "average\n",
      "operating\n",
      "products\n",
      "lower\n",
      "rates\n",
      "approximately\n",
      "price\n",
      "annual\n",
      "increased\n",
      "farm\n",
      "market\n",
      "volume\n",
      "higher\n",
      "equipment\n",
      "stock\n",
      "growth\n",
      "\n",
      "******************************\n",
      "remember\n",
      "tried\n",
      "coming\n",
      "talk\n",
      "feel\n",
      "friends\n",
      "call\n",
      "happened\n",
      "care\n",
      "trouble\n",
      "live\n",
      "gone\n",
      "soon\n",
      "maybe\n",
      "getting\n",
      "says\n",
      "dead\n",
      "longer\n",
      "leave\n",
      "looking\n",
      "\n",
      "******************************\n",
      "talked\n",
      "liked\n",
      "easier\n",
      "worry\n",
      "worse\n",
      "surprised\n",
      "cry\n",
      "forget\n",
      "gets\n",
      "sick\n",
      "afraid\n",
      "loved\n",
      "killed\n",
      "stands\n",
      "telling\n",
      "busy\n",
      "honor\n",
      "ship\n",
      "supposed\n",
      "minute\n",
      "\n",
      "******************************\n",
      "resources\n",
      "offer\n",
      "agencies\n",
      "essential\n",
      "require\n",
      "continue\n",
      "carry\n",
      "companies\n",
      "operations\n",
      "authority\n",
      "purposes\n",
      "project\n",
      "types\n",
      "include\n",
      "membership\n",
      "financial\n",
      "included\n",
      "funds\n",
      "construction\n",
      "professional\n",
      "\n",
      "******************************\n",
      "aspect\n",
      "atom\n",
      "mankind\n",
      "prove\n",
      "tragedy\n",
      "movements\n",
      "honest\n",
      "fairly\n",
      "happens\n",
      "feels\n",
      "conscious\n",
      "occasion\n",
      "revealed\n",
      "increasingly\n",
      "spite\n",
      "reader\n",
      "shared\n",
      "beings\n",
      "institution\n",
      "widely\n",
      "\n",
      "******************************\n",
      "learned\n",
      "meant\n",
      "happy\n",
      "knows\n",
      "apparently\n",
      "wish\n",
      "audience\n",
      "exactly\n",
      "note\n",
      "expect\n",
      "pretty\n",
      "stay\n",
      "thinking\n",
      "doubt\n",
      "wo\n",
      "wrong\n",
      "chance\n",
      "saying\n",
      "lived\n",
      "comes\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "CLUSTER_NUMBER = 100\n",
    "CLUSTER_THRESHOLD = 20\n",
    "# cluster words\n",
    "X = np.load(\"representation-\" + str(U_SIZE) + \".npy\")\n",
    "kmeans = KMeans(n_clusters = CLUSTER_NUMBER).fit(X)\n",
    "\n",
    "# sort words by distance to center\n",
    "word_groups = {i:PriorityQueue() for i in range(CLUSTER_NUMBER)}\n",
    "for i in range(len(X)):\n",
    "    representation = X[i]\n",
    "    word = idx2V[i]\n",
    "    center_id = kmeans.predict(X[i].reshape(1, -1))[0]\n",
    "    dist = norm(representation - kmeans.cluster_centers_[center_id])\n",
    "    word_groups[center_id].put((float(dist), word))\n",
    "\n",
    "# print only relatively large groups\n",
    "for i in range(CLUSTER_NUMBER):\n",
    "    if word_groups[i].qsize() < CLUSTER_THRESHOLD:\n",
    "        continue\n",
    "    count = 0\n",
    "    for j in range(CLUSTER_THRESHOLD):\n",
    "        if word_groups[i].empty():\n",
    "            break\n",
    "        print (word_groups[i].get()[1],)\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print\n",
    "    print (\"\\n******************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era             chorus          0.335989\n",
      "submarine       dynamic         0.253552\n",
      "changes         change          0.486755\n",
      "birth           death           0.517800\n",
      "sending         al              0.308579\n",
      "divorce         dick            0.266110\n",
      "cousin          heaven          0.460679\n",
      "assembly        mayor           0.516453\n",
      "language        literature      0.425120\n",
      "silent          stomach         0.382788\n",
      "evil            bad             0.441725\n",
      "educated        wit             0.186698\n",
      "minimal         polynomial      0.185531\n",
      "founded         crown           0.127797\n",
      "florida         di              0.129886\n",
      "wagon           parked          0.383355\n",
      "refer           h               0.287761\n",
      "arrive          franklin        0.246195\n",
      "explain         tried           0.480053\n",
      "examination     theories        0.314438\n",
      "cure            screw           0.191759\n",
      "span            preserved       0.169148\n",
      "automatically   pointing        0.285135\n",
      "painter         meredith        0.201946\n",
      "looks           guess           0.447092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "# use cosine distance\n",
    "tr = 1 - cosine_similarity(np.load(\"representation-\" + str(U_SIZE) + \".npy\"))\n",
    "np.fill_diagonal(tr, 0)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors = 2, metric = \"precomputed\")\n",
    "neigh.fit(tr, np.zeros((V_SIZE)))\n",
    "\n",
    "# find NN for 25 random words\n",
    "rand_inds = random.sample([i for i in range(V_SIZE)], 25)\n",
    "for i in rand_inds:\n",
    "    w = idx2V[i]\n",
    "    dist, ind = neigh.kneighbors(tr[i].reshape(1, -1))\n",
    "    uid = ind[0][1]\n",
    "    u = idx2V[uid]\n",
    "    print (\"%-15s %-15s %f\" %(w, u, dist[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
